{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Hitarthi\\Anaconda3\\lib\\site-packages\\IPython\\core\\magics\\pylab.py:160: UserWarning: pylab import has clobbered these variables: ['sample', 'test', 'product']\n",
      "`%matplotlib` prevents importing * from pylab and numpy\n",
      "  \"\\n`%matplotlib` prevents importing * from pylab and numpy\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6488665"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#IPython interpreter will import matplotlib and NumPy modules, convenient access to their functions\n",
    "%pylab inline \n",
    "#for regex\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "#collections : high performance container datatypes\n",
    "from collections import Counter\n",
    "from __future__ import division\n",
    "\n",
    "#First we need some text,from a file. Then we can break the text into words\n",
    "text_file = 'C:/Users/Hitarthi/Desktop/SEM 2/IDS/Homework 3/big.txt'\n",
    "data = open(text_file).read()\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#make tokens from the data\n",
    "#ignore all the punctuation and numbers, and anything that is not a letter\n",
    "#Normalize to lowercase\n",
    "\n",
    "\n",
    "#re.findall(pattern, string, flags=0)\n",
    "# '+' Causes the resulting RE to match 1 or more repetitions of the preceding RE.\n",
    "# ab+ will match ‘a’ followed by any non-zero number of ‘b’s; it will not match just ‘a’.\n",
    "\n",
    "def tokens(text):\n",
    "    return re.findall('[a-z]+', text.lower()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['this', 'is', 'a', 'test', 'this', 'is']"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens('This is: A test, 1, 2, 3, this is.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1105285"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "WORDS = tokens(data)\n",
    "len(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['the', 'project', 'gutenberg', 'ebook', 'of', 'the', 'adventures', 'of', 'sherlock', 'holmes']\n"
     ]
    }
   ],
   "source": [
    "#the first 10:\n",
    "print(WORDS[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'which our clear kissed at pulled of the by patient'"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#bag of words model, we ignore the order of words, but maintain their frequency\n",
    "#function to sample an n word sentence from a bag of words(WORDS)\n",
    "\n",
    "def sample(bag, n=10):\n",
    "    return ' '.join(random.choice(bag) for _ in range(n))\n",
    "\n",
    "sample(WORDS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({'a': 2, 'is': 2, 'it': 1, 'test': 2, 'this': 1})"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Another representation for a bag of words :\n",
    "#a Counter, which is a dictionary of {'word': count} pairs. \n",
    "\n",
    "Counter(tokens('Is this a test? It is a test!'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('the', 80030), ('of', 40025), ('and', 38313), ('to', 28766), ('in', 22050), ('a', 21155), ('that', 12512), ('he', 12401), ('was', 11410), ('it', 10681)]\n"
     ]
    }
   ],
   "source": [
    "#make a Counter for the big list of WORDS\n",
    "\n",
    "COUNTS = Counter(WORDS)\n",
    "print(COUNTS.most_common(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the 80030\n",
      "rare 83\n",
      "and 38313\n",
      "neverbeforeseen 0\n",
      "words 460\n"
     ]
    }
   ],
   "source": [
    "for w in tokens('the rare and neverbeforeseen words'):\n",
    "    print(w,COUNTS[w])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "TASK : Given a word w, find the most likely correction c = correct(w)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach: Try all candidate words c that are known words that are near w. Choose the most likely one.\n",
    "\n",
    "For now, in a trivial way: always prefer nearer, but when there is a tie on nearness, use the word with the highest WORDS count.\n",
    "\n",
    "Measure nearness by edit distance: the minimum number of deletions, transpositions, insertions, or replacements of characters. \n",
    "\n",
    "By trial and error, we determine that going out to edit distance 2 will give us reasonable results. Then we can define correct(w):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def correct(word):\n",
    "    #Generating all the words with edit distance of 0, 1 & 2\n",
    "    candidates = (known(edits0(word)) or \n",
    "                  known(edits1(word)) or \n",
    "                  known(edits2(word)) or \n",
    "                  [word])\n",
    "    return max(candidates, key=COUNTS.get)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def known(words):\n",
    "    #Return the subset of words that are actually in the dictionary.\"\n",
    "    return {w for w in words if w in COUNTS}\n",
    "\n",
    "def edits0(word): \n",
    "    return {word}\n",
    "\n",
    "def edits2(word):\n",
    "    return {e2 for e1 in edits1(word) for e2 in edits1(e1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def edits1(word):\n",
    "    pairs      = splits(word)\n",
    "    deletes    = [a+b[1:]           for (a, b) in pairs if b]\n",
    "    transposes = [a+b[1]+b[0]+b[2:] for (a, b) in pairs if len(b) > 1]\n",
    "    replaces   = [a+c+b[1:]         for (a, b) in pairs for c in alphabet if b]\n",
    "    inserts    = [a+c+b             for (a, b) in pairs for c in alphabet]\n",
    "    return set(deletes + transposes + replaces + inserts)\n",
    "\n",
    "def splits(word):\n",
    "    return [(word[:i], word[i:]) \n",
    "            for i in range(len(word)+1)]\n",
    "\n",
    "alphabet = 'abcdefghijklmnopqrstuvwxyz'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 'wird'), ('w', 'ird'), ('wi', 'rd'), ('wir', 'd'), ('wird', '')]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "splits('wird')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'wird'}\n"
     ]
    }
   ],
   "source": [
    "print(edits0('wird'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "234\n"
     ]
    }
   ],
   "source": [
    "print(len(edits1('wird')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24254\n"
     ]
    }
   ],
   "source": [
    "print(len(edits2('wird')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "#re.sub(pattern, repl, string, count=0, flags=0) \n",
    "#Return the string obtained by replacing the leftmost non-overlapping occurrences of pattern in string by the replacement repl.\n",
    "#If the pattern isn’t found, string is returned unchanged.\n",
    "\n",
    "def correct_text(text):\n",
    "    return re.sub('[a-zA-Z]+', correct_match, text)\n",
    "\n",
    "def correct_match(match):\n",
    "    word = match.group()\n",
    "    return case_of(word)(correct(word.lower()))\n",
    "\n",
    "\n",
    "#str.Title()\n",
    "#parameters:str is a valid string which we need to convert.\n",
    "#return: This function returns a string which has first letter in each word uppercase and remaining lowercase. \n",
    "\n",
    "def case_of(text):\n",
    "    return (str.upper if text.isupper() else\n",
    "            str.lower if text.islower() else\n",
    "            str.title if text.istitle() else\n",
    "            str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Spelling Errors IN something. Whatever; unusual mistakes, Hitarthi ?'"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct_text('Speling Errurs IN somethink. Whutever; unusuel misteakes, Hitarthi ?')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the text \"three, too, one, blastoff!\" we might want to correct \"too\" with \"two\", even though \"too\" is in the dictionary. We can do better if we look at a sequence of words, not just an individual word one at a time. \n",
    "\n",
    "\n",
    "Counts to Probabilities of Word Sequences : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# probability of a word, P(w).\n",
    "# pdist:takes as input a Counter (a bag of words)\n",
    "# returns a function that acts as a probability distribution over all possible words. \n",
    "\n",
    "\n",
    "def pdist(counter):\n",
    "    \"Make a probability distribution, given evidence from a Counter.\"\n",
    "    N = sum(list(counter.values()))\n",
    "    return lambda x: counter[x]/N\n",
    "\n",
    "P = pdist(COUNTS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0724066643445 the\n",
      "0.00884296810325 is\n",
      "0.000821507574969 most\n",
      "0.00025966153526 common\n",
      "0.000269613719538 word\n",
      "0.0199496057578 in\n",
      "0.000190900989338 english\n"
     ]
    }
   ],
   "source": [
    "for w in tokens('\"The\" is most common word in English'):\n",
    "    print(P(w), w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " what is the probability of a sequence of words? Use the definition of a joint probability:\n",
    "\n",
    "P(w1…wn)=P(w1)×P(w2∣w1)×P(w3∣w1w2)…×…P(wn∣w1…wn−1)P(w1…wn)=P(w1)×P(w2∣w1)×P(w3∣w1w2)…×…P(wn∣w1…wn−1)\n",
    "\n",
    "The bag of words model assumes that each word is drawn from the bag independently of the others. This gives us the wrong approximation:\n",
    "\n",
    "P(w1…wn)=P(w1)×P(w2)×P(w3)…×…P(wn)P(w1…wn)=P(w1)×P(w2)×P(w3)…×…P(wn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# \"Probability of words, assuming each word is independent of others.\"\n",
    "\n",
    "def Pwords(words):\n",
    "    return product(P(w) for w in words)\n",
    "\n",
    "# \"Multiply the numbers together.\n",
    "def product(nums):\n",
    "    result = 1\n",
    "    for x in nums:\n",
    "        result *= x\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.9833963328e-11 this is a test\n",
      "8.63747202302e-16 this is a unusual test\n",
      "0.0 this is a neverbeforeseen test\n"
     ]
    }
   ],
   "source": [
    "tests = ['this is a test',\n",
    "         'this is a unusual test','this is a neverbeforeseen test']\n",
    "\n",
    "for test in tests:\n",
    "    print(Pwords(tokens(test)), test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
